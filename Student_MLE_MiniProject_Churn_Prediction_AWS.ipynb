{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb4568ce",
   "metadata": {},
   "source": [
    "# Save to Feature Store with a SageMaker Processing Job\n",
    "\n",
    "<div class=\"alert alert-info\"> üí° <strong> Quick Start </strong>\n",
    "To save your processed data to feature store, <strong><a style=\"color: #0397a7 \" href=\"#Create-Feature-Group\">\n",
    "    <u>Click here to create a feature group</u></a> and follow the instruction to run a SageMaker processing job.\n",
    "</strong>\n",
    "</div>\n",
    "\n",
    "This notebook uses Amazon SageMaker Feature Store (Feature Store) to create a feature group, \n",
    "executes your data flow `sp_featStore_2025Nov11.flow` on the entire dataset using a SageMaker \n",
    "Processing Job and ingest processed data to Feature Store. \n",
    "\n",
    "---\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Create Feature Group](#Create-Feature-Group)\n",
    "   1. [Define Feature Group](#Define-Feature-Group)\n",
    "   1. [Configure Feature Group](#Configure-Feature-Group)\n",
    "   1. [Initialize & Create Feature Group](#Initialize-&-Create-Feature-Group)\n",
    "1. [Processing Job: Inputs and Outputs](#Inputs-and-Outputs)\n",
    "1. [Run Processing Job](#Run-Processing-Job)\n",
    "   1. [Job Configurations](#Job-Configurations)\n",
    "   1. [Create Processing Job](#Create-Processing-Job)\n",
    "   1. [Job Status & Output Location](#Job-Status-&-Output-Location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69a4f99",
   "metadata": {},
   "source": [
    "## Create Feature Group\n",
    "\n",
    "_What is a feature group_\n",
    "\n",
    "A single feature corresponds to a column in your dataset. A feature group is a predefined schema for a \n",
    "collection of features - each feature in the feature group has a specified data type and name. \n",
    "A single record in a feature group corresponds to a row in your dataframe. A feature store is a \n",
    "collection of feature groups. To learn more about SageMaker Feature Store, see \n",
    "[Amazon Feature Store Documentation](http://docs.aws.amazon.com/sagemaker/latest/dg/feature-store.html).\n",
    "\n",
    "### Define Feature Group\n",
    "Select Record identifier and Event time feature name. These are required parameters for feature group\n",
    "creation.\n",
    "* **Record identifier name** is the name of the feature defined in the feature group's feature definitions \n",
    "whose value uniquely identifies a Record defined in the feature group's feature definitions.\n",
    "* **Event time feature name** is the name of the EventTime feature of a Record in FeatureGroup. An EventTime \n",
    "is a timestamp that represents the point in time when a new event occurs that corresponds to the creation or \n",
    "update of a Record in the FeatureGroup. All Records in the FeatureGroup must have a corresponding EventTime.\n",
    "\n",
    "<div class=\"alert alert-info\"> üí°Record identifier and Event time feature name are required \n",
    "for feature group. After filling in the values, you can choose <b>Run Selected Cell and All Below</b> \n",
    "from the Run Menu from the menu bar. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cdae220",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_identifier_feature_name = \"custid\"\n",
    "if record_identifier_feature_name is None:\n",
    "   raise SystemExit(\"Select a column name as the feature group record identifier.\")\n",
    "\n",
    "event_time_feature_name = \"lastorder\"\n",
    "if event_time_feature_name is None:\n",
    "   raise SystemExit(\"Select a column name as the event time feature name.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05ea184",
   "metadata": {},
   "source": [
    "### Feature Definitions\n",
    "The following is a list of the feature names and feature types of the final dataset that will be produced \n",
    "when your data flow is used to process your input dataset. These are automatically generated from the \n",
    "step `Custom Pyspark` from `Source: Answers.Csv`. To save from a different step, go to Canvas to \n",
    "select a new step to export.\n",
    "\n",
    "<div class=\"alert alert-info\"> üí° <strong> Configurable Settings </strong>\n",
    "\n",
    "1. You can select a subset of the features. By default all columns of the result dataframe will be used as \n",
    "features.\n",
    "2. You can change the Canvas data type to one of the Feature Store supported types \n",
    "(<b>Integral</b>, <b>Fractional</b>, or <b>String</b>). The default type is set to <b>String</b>. \n",
    "This means that, if a column in your dataset is not a <b>float</b> or <b>long</b> type, it will default \n",
    "to <b>String</b> in your Feature Store.\n",
    "\n",
    "For <b>Event Time</b> features, make sure the format follows the feature store\n",
    "<strong>\n",
    "    <a style=\"color: #0397a7 \" href=\"https://docs.aws.amazon.com/sagemaker/latest/dg/feature-store-quotas.html#feature-store-data-types\">\n",
    "    <u>Event Time feature format</u>\n",
    "    </a>\n",
    "</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f0924e",
   "metadata": {},
   "source": [
    "The following is a list of the feature names and data types of the final dataset that will be produced when your data flow is used to process your input dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d3c7c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_schemas = [\n",
    "    {\n",
    "        \"name\": \"retained\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"custid\",\n",
    "        \"type\": \"float\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"created\",\n",
    "        \"type\": \"datetime\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"firstorder\",\n",
    "        \"type\": \"datetime\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"lastorder\",\n",
    "        \"type\": \"datetime\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"esent\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"eopenrate\",\n",
    "        \"type\": \"float\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"eclickrate\",\n",
    "        \"type\": \"float\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"avgorder\",\n",
    "        \"type\": \"float\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"ordfreq\",\n",
    "        \"type\": \"float\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"paperless\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"refill\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"doorstep\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"favday\",\n",
    "        \"type\": \"float\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"city\",\n",
    "        \"type\": \"float\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4571d610",
   "metadata": {},
   "source": [
    "Below we create the SDK input for those feature definitions. Some schema types in Canvas are not \n",
    "supported by Feature Store. The following will create a default_FG_type set to String for these types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02f7034f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.feature_store.feature_definition import FeatureDefinition\n",
    "from sagemaker.feature_store.feature_definition import FeatureTypeEnum\n",
    "\n",
    "default_feature_type = FeatureTypeEnum.STRING\n",
    "column_to_feature_type_mapping = {\n",
    "    \"float\": FeatureTypeEnum.FRACTIONAL,\n",
    "    \"long\": FeatureTypeEnum.INTEGRAL\n",
    "}\n",
    "\n",
    "feature_definitions = [\n",
    "    FeatureDefinition(\n",
    "        feature_name=column_schema['name'], \n",
    "        feature_type=column_to_feature_type_mapping.get(column_schema['type'], default_feature_type)\n",
    "    ) for column_schema in column_schemas\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb5472e",
   "metadata": {},
   "source": [
    "## Configure Feature Group\n",
    "\n",
    "<div class=\"alert alert-info\"> üí° <strong> Configurable Settings </strong>\n",
    "\n",
    "1. <b>feature_group_name</b>: name of the feature group.\n",
    "1. <b>feature_store_offline_s3_uri</b>: SageMaker FeatureStore writes the data in the OfflineStore of a FeatureGroup to a S3 location owned by you.\n",
    "1. <b>enable_online_store</b>: controls if online store is enabled. Enabling the online store allows quick access to the latest value for a Record via the GetRecord API.\n",
    "1. <b>iam_role</b>: IAM role for executing the processing job.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c02e96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bucket: sagemaker-us-east-1-417311687551\n",
      "iam_role: arn:aws:iam::417311687551:role/service-role/AmazonSageMaker-ExecutionRole-20251101T200692\n",
      "Feature Group Name: FG-sp-featStore-2025Nov11-d73341ef\n",
      "feature_store_offline_s3_uri: s3://sagemaker-us-east-1-417311687551\n"
     ]
    }
   ],
   "source": [
    "from time import gmtime, strftime\n",
    "import uuid\n",
    "import sagemaker \n",
    "\n",
    "# Sagemaker session\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "# You can configure this with your own bucket name, e.g.\n",
    "# bucket = <my-own-storage-bucket>\n",
    "bucket = sess.default_bucket()\n",
    "print(f\"bucket: {bucket}\")\n",
    "\n",
    "# IAM role for executing the processing job.\n",
    "iam_role = sagemaker.get_execution_role()\n",
    "print(f\"iam_role: {iam_role}\")\n",
    "\n",
    "# flow name and an unique ID for this export (used later as the processing job name for the export)\n",
    "flow_name = \"sp-featStore-2025Nov11\"\n",
    "flow_export_id = f\"{strftime('%d-%H-%M-%S', gmtime())}-{str(uuid.uuid4())[:8]}\"\n",
    "flow_export_name = f\"flow-{flow_export_id}\"\n",
    "\n",
    "# feature group name, with flow_name and an unique id. You can give it a customized name\n",
    "feature_group_name = f\"FG-{flow_name}-{str(uuid.uuid4())[:8]}\"\n",
    "print(f\"Feature Group Name: {feature_group_name}\")\n",
    "\n",
    "# SageMaker FeatureStore writes the data in the OfflineStore of a FeatureGroup to a \n",
    "# S3 location owned by you.\n",
    "feature_store_offline_s3_uri = 's3://' + bucket\n",
    "print(f\"feature_store_offline_s3_uri: {feature_store_offline_s3_uri}\")\n",
    "\n",
    "# controls if online store is enabled. Enabling the online store allows quick access to \n",
    "# the latest value for a Record via the GetRecord API.\n",
    "enable_online_store = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f832547",
   "metadata": {},
   "source": [
    "### Initialize & Create Feature Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "451ee61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Boto3 session that is required to create feature group\n",
    "import boto3\n",
    "from sagemaker.session import Session\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "boto_session = boto3.Session(region_name=region)\n",
    "\n",
    "sagemaker_client = boto_session.client(service_name='sagemaker', region_name=region)\n",
    "featurestore_runtime = boto_session.client(service_name='sagemaker-featurestore-runtime', region_name=region)\n",
    "\n",
    "feature_store_session = Session(\n",
    "    boto_session=boto_session,\n",
    "    sagemaker_client=sagemaker_client,\n",
    "    sagemaker_featurestore_runtime_client=featurestore_runtime\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e3c2b0",
   "metadata": {},
   "source": [
    "Feature group is initialized and created below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4607999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FeatureGroupArn': 'arn:aws:sagemaker:us-east-1:417311687551:feature-group/FG-sp-featStore-2025Nov11-d73341ef',\n",
       " 'ResponseMetadata': {'RequestId': 'fbfbf8a8-ac63-4090-b4a5-609e7ba98040',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'fbfbf8a8-ac63-4090-b4a5-609e7ba98040',\n",
       "   'strict-transport-security': 'max-age=47304000; includeSubDomains',\n",
       "   'x-frame-options': 'DENY',\n",
       "   'content-security-policy': \"frame-ancestors 'none'\",\n",
       "   'cache-control': 'no-cache, no-store, must-revalidate',\n",
       "   'x-content-type-options': 'nosniff',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '111',\n",
       "   'date': 'Tue, 02 Dec 2025 01:27:26 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "\n",
    "feature_group = FeatureGroup(\n",
    "    name=feature_group_name, sagemaker_session=feature_store_session, feature_definitions=feature_definitions)\n",
    "\n",
    "feature_group.create(\n",
    "    s3_uri=feature_store_offline_s3_uri,\n",
    "    record_identifier_name=record_identifier_feature_name,\n",
    "    event_time_feature_name=event_time_feature_name,\n",
    "    role_arn=iam_role,\n",
    "    enable_online_store=enable_online_store\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eff9bea",
   "metadata": {},
   "source": [
    "Invoke the Feature Store API to create the feature group and wait until it is ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a600c454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for Feature Group Creation\n",
      "Waiting for Feature Group Creation\n",
      "Waiting for Feature Group Creation\n",
      "Waiting for Feature Group Creation\n",
      "Waiting for Feature Group Creation\n",
      "FeatureGroup FG-sp-featStore-2025Nov11-d73341ef successfully created.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "def wait_for_feature_group_creation_complete(feature_group):\n",
    "    \"\"\"Helper function to wait for the completions of creating a feature group\"\"\"\n",
    "    response = feature_group.describe()\n",
    "    status = response.get(\"FeatureGroupStatus\")\n",
    "    while status == \"Creating\":\n",
    "        print(\"Waiting for Feature Group Creation\")\n",
    "        time.sleep(5)\n",
    "        response = feature_group.describe()\n",
    "        status = response.get(\"FeatureGroupStatus\")\n",
    "\n",
    "    if status != \"Created\":\n",
    "        print(f\"Failed to create feature group, response: {response}\")\n",
    "        failureReason = response.get(\"FailureReason\", \"\")\n",
    "        raise SystemExit(\n",
    "            f\"Failed to create feature group {feature_group.name}, status: {status}, reason: {failureReason}\"\n",
    "        )\n",
    "    print(f\"FeatureGroup {feature_group.name} successfully created.\")\n",
    "\n",
    "wait_for_feature_group_creation_complete(feature_group=feature_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b1a0fb",
   "metadata": {},
   "source": [
    "Now that the feature group is created, You will use a processing job to process your \n",
    "        data at scale and ingest the transformed data into this feature group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3b8147",
   "metadata": {},
   "source": [
    "# Inputs and Outputs\n",
    "\n",
    "The below settings configure the inputs and outputs for the flow export.\n",
    "\n",
    "<div class=\"alert alert-info\"> üí° <strong> Configurable Settings </strong>\n",
    "\n",
    "In <b>Input - Source</b> you can configure the data sources that will be used as input by Canvas\n",
    "\n",
    "1. For S3 sources, configure the source attribute that points to the input S3 prefixes\n",
    "2. For all other sources, configure attributes like query_string, database in the source's \n",
    "<b>DatasetDefinition</b> object.\n",
    "\n",
    "If you modify the inputs the provided data must have the same schema and format as the data used in the Flow. \n",
    "You should also re-execute the cells in this section if you have modified the settings in any data sources.\n",
    "\n",
    "Parametrized data sources will be ignored when creating ProcessingInputs, and will directly read from the source.\n",
    "Network isolation is not supported for parametrized data sources.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "551b147c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.dataset_definition.inputs import AthenaDatasetDefinition, DatasetDefinition, RedshiftDatasetDefinition\n",
    "\n",
    "data_sources = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ade8ace",
   "metadata": {},
   "source": [
    "## Input - S3 Source: storedata_total-csv-fmt.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "285db1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sources.append(ProcessingInput(\n",
    "    source=\"s3://amzn-s3-springsource-ml-churn/spring_source/storedata_total-csv-fmt.csv\", # You can override this to point to other dataset on S3\n",
    "    destination=\"/opt/ml/processing/storedata_total-csv-fmt.csv\",\n",
    "    input_name=\"storedata_total-csv-fmt.csv\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    "    s3_input_mode=\"File\",\n",
    "    s3_data_distribution_type=\"FullyReplicated\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e5b2ab",
   "metadata": {},
   "source": [
    "### Output: Feature Store \n",
    "\n",
    "Below are the inputs required by the SageMaker Python SDK to launch a processing job with feature store as an output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "062f824c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import FeatureStoreOutput\n",
    "\n",
    "# Output name is auto-generated from the select node's ID + output name from the flow file.\n",
    "output_name = \"2c0a7493-90fc-41a4-b067-bf42659bf1eb.default\"\n",
    "\n",
    "processing_job_output = ProcessingOutput(\n",
    "    output_name=output_name,\n",
    "    app_managed=True,\n",
    "    feature_store_output=FeatureStoreOutput(feature_group_name=feature_group_name),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0657a38",
   "metadata": {},
   "source": [
    "## Upload Flow to S3\n",
    "\n",
    "To use the data flow as an input to the processing job, first upload your flow file to Amazon S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3211c177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading flow file from current notebook working directory: /home/sagemaker-user/springboard\n",
      "Data flow sp_featStore_2025Nov11.flow uploaded to s3://sagemaker-us-east-1-417311687551/data_wrangler_flows/flow-02-01-27-25-85db4acd.flow\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "# name of the flow file which should exist in the current notebook working directory\n",
    "flow_file_name = \"sp_featStore_2025Nov11.flow\"\n",
    "\n",
    "# Load .flow file from current notebook working directory \n",
    "!echo \"Loading flow file from current notebook working directory: $PWD\"\n",
    "\n",
    "with open(flow_file_name) as f:\n",
    "    flow = json.load(f)\n",
    "\n",
    "# Upload flow to S3\n",
    "s3_client = boto3.client(\"s3\")\n",
    "s3_client.upload_file(flow_file_name, bucket, f\"data_wrangler_flows/{flow_export_name}.flow\", ExtraArgs={\"ServerSideEncryption\": \"aws:kms\"})\n",
    "\n",
    "flow_s3_uri = f\"s3://{bucket}/data_wrangler_flows/{flow_export_name}.flow\"\n",
    "\n",
    "print(f\"Data flow {flow_file_name} uploaded to {flow_s3_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e942ba",
   "metadata": {},
   "source": [
    "The data flow is also provided to the Processing Job as an input source which we configure below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84ecb82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input - Flow: sp_featStore_2025Nov11.flow\n",
    "flow_input = ProcessingInput(\n",
    "    source=flow_s3_uri,\n",
    "    destination=\"/opt/ml/processing/flow\",\n",
    "    input_name=\"flow\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    "    s3_input_mode=\"File\",\n",
    "    s3_data_distribution_type=\"FullyReplicated\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5f3614",
   "metadata": {},
   "source": [
    "# Run Processing Job \n",
    "## Job Configurations\n",
    "\n",
    "<div class=\"alert alert-info\"> üí° <strong> Configurable Settings </strong>\n",
    "\n",
    "You can configure the following settings for Processing Jobs. If you change any configurations you will \n",
    "need to re-execute this and all cells below it by selecting the Run menu above and click \n",
    "<b>Run Selected Cells and All Below</b>\n",
    "\n",
    "1. IAM role for executing the processing job. \n",
    "2. A unique name of the processing job. Give a unique name every time you re-execute processing jobs\n",
    "3. Canvas Container URL.\n",
    "4. Instance count, instance type and storage volume size in GB.\n",
    "5. Content type for each output. Canvas supports CSV as default and Parquet.\n",
    "6. Network Isolation settings\n",
    "7. KMS key to encrypt output data\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f95de738",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "from sagemaker import image_uris\n",
    "\n",
    "# IAM role for executing the processing job.\n",
    "iam_role = sagemaker.get_execution_role()\n",
    "\n",
    "# Unique processing job name. Give a unique name every time you re-execute processing jobs.\n",
    "processing_job_name = f\"data-wrangler-flow-processing-{flow_export_id}\"\n",
    "\n",
    "# Canvas Container URL.\n",
    "container_uri = \"599662218115.dkr.ecr.us-east-1.amazonaws.com/sagemaker-data-wrangler-container:5.x\"\n",
    "# Pinned Canvas Container URL.\n",
    "container_uri_pinned = \"599662218115.dkr.ecr.us-east-1.amazonaws.com/sagemaker-data-wrangler-container:5.0.9\"\n",
    "\n",
    "# Processing Job Instance count and instance type.\n",
    "instance_count = 2\n",
    "instance_type = \"ml.t3.xlarge\" #\"ml.m5.4xlarge\"\n",
    "\n",
    "# Size in GB of the EBS volume to use for storing data during processing.\n",
    "volume_size_in_gb = 30\n",
    "\n",
    "\n",
    "# Content type for each output. Canvas supports CSV as default and Parquet.\n",
    "output_content_type = \"CSV\"\n",
    "\n",
    "# Delimiter to use for the output if the output content type is CSV. Uncomment to set.\n",
    "# delimiter = \",\"\n",
    "\n",
    "# Compression to use for the output. Uncomment to set.\n",
    "# compression = \"gzip\"\n",
    "\n",
    "# Configuration for partitioning the output. Uncomment to set.\n",
    "# \"num_partition\" sets the number of partitions/files written in the output.\n",
    "# \"partition_by\" sets the column names to partition the output by.\n",
    "# partition_config = {\n",
    "#     \"num_partitions\": 1,\n",
    "#     \"partition_by\": [\"column_name_1\", \"column_name_2\"],\n",
    "# }\n",
    "\n",
    "# Network Isolation mode; default is off.\n",
    "enable_network_isolation = False\n",
    "\n",
    "# List of tags to be passed to the processing job.\n",
    "user_tags = None\n",
    "\n",
    "# Output configuration used as processing job container arguments. Only applies when writing to S3.\n",
    "# Uncomment to set additional configurations.\n",
    "output_config = {\n",
    "    output_name: {\n",
    "        \"content_type\": output_content_type,\n",
    "        # \"delimiter\": delimiter,\n",
    "        # \"compression\": compression,\n",
    "        # \"partition_config\": partition_config,\n",
    "    }\n",
    "}\n",
    "\n",
    "# Refit configuration determines whether Canvas refits the trainable parameters on the entire dataset. \n",
    "# When True, the processing job relearns the parameters and outputs a new flow file.\n",
    "# You can specify the name of the output flow file under 'output_flow'.\n",
    "# Note: There are length constraints on the container arguments (max 256 characters).\n",
    "use_refit = False\n",
    "refit_trained_params = {\n",
    "    \"refit\": use_refit,\n",
    "    \"output_flow\": f\"data-wrangler-flow-processing-{flow_export_id}.flow\"\n",
    "}\n",
    "\n",
    "# KMS key for per object encryption; default is None.\n",
    "kms_key = None\n",
    "\n",
    "# Inference parameters determine whether Canvas generates an inference artifact at the end of the job run.\n",
    "# When set, the processing job generates an inference artifact and uploads it to S3 under the S3 prefix of `flow_s3_uri`.\n",
    "# You can specify the name of the output artifact with 'inference_artifact_name'.\n",
    "use_inference_params = False\n",
    "inference_artifact_name = f\"data-wrangler-flow-processing-{flow_export_id}.tar.gz\"\n",
    "inference_params = {\n",
    "    \"inference_artifact_name\": inference_artifact_name,\n",
    "    \"output_node_id\": output_name.split(\".\")[0]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b43b74",
   "metadata": {},
   "source": [
    "### Job arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64ba6e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_arguments = [f\"--output-config '{json.dumps(output_config)}'\"]\n",
    "if use_refit:\n",
    "    job_arguments.append(f\"--refit-trained-params '{json.dumps(refit_trained_params)}'\")\n",
    "if use_inference_params:\n",
    "    job_arguments.append(f\"--inference-params '{json.dumps(inference_params)}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353e54e9",
   "metadata": {},
   "source": [
    "### (Optional) Configure Spark Cluster Driver Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa3a5597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Spark memory configuration. Change to specify the driver and executor memory in MB for the Spark cluster during processing.\n",
    "driver_memory_in_mb = 55742\n",
    "executor_memory_in_mb = 55742\n",
    "\n",
    "config = json.dumps({\n",
    "    \"Classification\": \"spark-defaults\",\n",
    "    \"Properties\": {\n",
    "        \"spark.driver.memory\": f\"{driver_memory_in_mb}m\",\n",
    "        \"spark.executor.memory\": f\"{executor_memory_in_mb}m\"\n",
    "    }\n",
    "})\n",
    "\n",
    "# Provides the spark config file to processing job and set the cluster driver memory. Uncomment to set.\n",
    "# config_file = f\"config-{flow_export_id}.json\"\n",
    "# with open(config_file, \"w\") as f:\n",
    "#     f.write(config)\n",
    "\n",
    "# config_s3_path = f\"spark_configuration/{processing_job_name}/configuration.json\"\n",
    "# config_s3_uri = f\"s3://{bucket}/{config_s3_path}\"\n",
    "# s3_client.upload_file(config_file, bucket, config_s3_path, ExtraArgs={\"ServerSideEncryption\": \"aws:kms\"})\n",
    "# print(f\"Spark Config file uploaded to {config_s3_uri}\")\n",
    "# os.remove(config_file)\n",
    "\n",
    "# data_sources.append(ProcessingInput(\n",
    "#     source=config_s3_uri,\n",
    "#     destination=\"/opt/ml/processing/input/conf\",\n",
    "#     input_name=\"spark-config\",\n",
    "#     s3_data_type=\"S3Prefix\",\n",
    "#     s3_input_mode=\"File\",\n",
    "#     s3_data_distribution_type=\"FullyReplicated\"\n",
    "# ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1d948c",
   "metadata": {},
   "source": [
    "## Create Processing Job\n",
    "\n",
    "To launch a Processing Job, you will use the SageMaker Python SDK to create a Processor function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a523b6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup processing job network configuration\n",
    "from sagemaker.network import NetworkConfig\n",
    "\n",
    "network_config = NetworkConfig(\n",
    "    enable_network_isolation=enable_network_isolation,\n",
    "    security_group_ids=None,\n",
    "    subnets=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c028086",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating processing-job with name data-wrangler-flow-processing-02-01-27-25-85db4acd\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import Processor\n",
    "\n",
    "processor = Processor(\n",
    "    role=iam_role,\n",
    "    image_uri=container_uri,\n",
    "    instance_count=instance_count,\n",
    "    instance_type=instance_type,\n",
    "    volume_size_in_gb=volume_size_in_gb,\n",
    "    network_config=network_config,\n",
    "    sagemaker_session=sess,\n",
    "    output_kms_key=kms_key,\n",
    "    tags=user_tags\n",
    ")\n",
    "\n",
    "# Start Job\n",
    "processor.run(\n",
    "    inputs=[flow_input] + data_sources, \n",
    "    outputs=[processing_job_output],\n",
    "    arguments=job_arguments,\n",
    "    wait=False,\n",
    "    logs=False,\n",
    "    job_name=processing_job_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4330be86",
   "metadata": {},
   "source": [
    "## Job Status & S3 Output Location\n",
    "\n",
    "Below you wait for processing job to finish. If it finishes successfully, your feature group should be populated \n",
    "with transformed feature values. In addition the raw parameters used by the Processing Job will be printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1cf2a3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iam_role: arn:aws:iam::417311687551:role/service-role/AmazonSageMaker-ExecutionRole-20251101T200692\n",
      "*"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ </span><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">Traceback </span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #ff0000; text-decoration-color: #ff0000\"> ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> in &lt;module&gt;:2                                                                                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1 </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>(<span style=\"color: #808000; text-decoration-color: #808000\">f\"iam_role: {</span>iam_role<span style=\"color: #808000; text-decoration-color: #808000\">}\"</span>)                                                               <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span>2 job_result = <span style=\"font-weight: bold; text-decoration: underline\">sess.wait_for_processing_job(processing_job_name)</span>                               <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3 </span>job_result                                                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4 </span>                                                                                             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">/opt/conda/lib/python3.12/site-packages/sagemaker/</span><span style=\"font-weight: bold\">session.py</span>:5524 in wait_for_processing_job     <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5521 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #808000; text-decoration-color: #808000\">exceptions.UnexpectedStatusException: If the processing job fails.</span>            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5522 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">‚îÇ   ‚îÇ   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                               <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5523 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span>desc = _wait_until(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">lambda</span>: _processing_job_status(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.sagemaker_client, job), p  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span>5524 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span><span style=\"font-weight: bold; text-decoration: underline\">_check_job_status(job, desc, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold; text-decoration: underline\">\"ProcessingJobStatus\"</span><span style=\"font-weight: bold; text-decoration: underline\">)</span>                               <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5525 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> desc                                                                       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5526 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   </span>                                                                                      <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5527 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span><span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">wait_for_compilation_job</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, job, poll=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">5</span>):                                      <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">/opt/conda/lib/python3.12/site-packages/sagemaker/</span><span style=\"font-weight: bold\">session.py</span>:8835 in _check_job_status           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">8832 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span>allowed_statuses=[<span style=\"color: #808000; text-decoration-color: #808000\">\"Completed\"</span>, <span style=\"color: #808000; text-decoration-color: #808000\">\"Stopped\"</span>],                                <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">8833 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span>actual_status=status,                                                     <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">8834 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span>)                                                                             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span>8835 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff; font-weight: bold; text-decoration: underline\">raise</span><span style=\"font-weight: bold; text-decoration: underline\"> exceptions.UnexpectedStatusException(</span>                                       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">8836 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"font-weight: bold; text-decoration: underline\">message=message,</span>                                                              <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">8837 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"font-weight: bold; text-decoration: underline\">allowed_statuses=[</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold; text-decoration: underline\">\"Completed\"</span><span style=\"font-weight: bold; text-decoration: underline\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold; text-decoration: underline\">\"Stopped\"</span><span style=\"font-weight: bold; text-decoration: underline\">],</span>                                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">8838 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"font-weight: bold; text-decoration: underline\">actual_status=status,</span>                                                         <span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚îÇ</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">UnexpectedStatusException: </span>Error for Processing job data-wrangler-flow-processing-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span>-85db4acd: Failed. \n",
       "Reason: ClientError: ValidationException: Access denied for repository: sagemaker-data-wrangler-container in \n",
       "registry ID: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599662218115</span>. Please check if your ECR repository and image exist and role \n",
       "arn:aws:iam::<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">417311687551</span>:role/service-role/AmazonSageMaker-ExecutionRole-20251101T200692 has proper pull \n",
       "permissions for SageMaker: ecr:BatchCheckLayerAvailability, ecr:BatchGetImage, ecr:GetDownloadUrlForLayer\n",
       "        status code: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">400</span>, request id: <span style=\"color: #ffff00; text-decoration-color: #ffff00\">e5155cd2-f047-496d-aee9-2e668e099803</span>. Check troubleshooting guide for common \n",
       "errors: <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-python-sdk-troubleshooting.html</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;255;0;0m‚ï≠‚îÄ\u001b[0m\u001b[38;2;255;0;0m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[38;2;255;0;0m \u001b[0m\u001b[1;38;2;255;0;0mTraceback \u001b[0m\u001b[1;2;38;2;255;0;0m(most recent call last)\u001b[0m\u001b[38;2;255;0;0m \u001b[0m\u001b[38;2;255;0;0m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[38;2;255;0;0m‚îÄ‚ïÆ\u001b[0m\n",
       "\u001b[38;2;255;0;0m‚îÇ\u001b[0m in <module>:2                                                                                    \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
       "\u001b[38;2;255;0;0m‚îÇ\u001b[0m                                                                                                  \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
       "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m1 \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33miam_role: \u001b[0m\u001b[33m{\u001b[0miam_role\u001b[33m}\u001b[0m\u001b[33m\"\u001b[0m)                                                               \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
       "\u001b[38;2;255;0;0m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m2 job_result = \u001b[1;4msess.wait_for_processing_job(processing_job_name)\u001b[0m                               \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
       "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m3 \u001b[0mjob_result                                                                                   \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
       "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m4 \u001b[0m                                                                                             \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
       "\u001b[38;2;255;0;0m‚îÇ\u001b[0m                                                                                                  \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
       "\u001b[38;2;255;0;0m‚îÇ\u001b[0m \u001b[2m/opt/conda/lib/python3.12/site-packages/sagemaker/\u001b[0m\u001b[1msession.py\u001b[0m:5524 in wait_for_processing_job     \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
       "\u001b[38;2;255;0;0m‚îÇ\u001b[0m                                                                                                  \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
       "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m5521 \u001b[0m\u001b[2;33m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[33mexceptions.UnexpectedStatusException: If the processing job fails.\u001b[0m            \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
       "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m5522 \u001b[0m\u001b[2;33m‚îÇ   ‚îÇ   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                               \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
       "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m5523 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0mdesc = _wait_until(\u001b[94mlambda\u001b[0m: _processing_job_status(\u001b[96mself\u001b[0m.sagemaker_client, job), p  \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
       "\u001b[38;2;255;0;0m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m5524 \u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[1;4m_check_job_status(job, desc, \u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4;33mProcessingJobStatus\u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4m)\u001b[0m                               \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
       "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m5525 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[94mreturn\u001b[0m desc                                                                       \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
       "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m5526 \u001b[0m\u001b[2m‚îÇ   \u001b[0m                                                                                      \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
       "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m5527 \u001b[0m\u001b[2m‚îÇ   \u001b[0m\u001b[94mdef\u001b[0m\u001b[90m \u001b[0m\u001b[92mwait_for_compilation_job\u001b[0m(\u001b[96mself\u001b[0m, job, poll=\u001b[94m5\u001b[0m):                                      \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
       "\u001b[38;2;255;0;0m‚îÇ\u001b[0m                                                                                                  \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
       "\u001b[38;2;255;0;0m‚îÇ\u001b[0m \u001b[2m/opt/conda/lib/python3.12/site-packages/sagemaker/\u001b[0m\u001b[1msession.py\u001b[0m:8835 in _check_job_status           \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
       "\u001b[38;2;255;0;0m‚îÇ\u001b[0m                                                                                                  \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
       "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m8832 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0mallowed_statuses=[\u001b[33m\"\u001b[0m\u001b[33mCompleted\u001b[0m\u001b[33m\"\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33mStopped\u001b[0m\u001b[33m\"\u001b[0m],                                \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
       "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m8833 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0mactual_status=status,                                                     \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
       "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m8834 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m)                                                                             \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
       "\u001b[38;2;255;0;0m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m8835 \u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[1;4;94mraise\u001b[0m\u001b[1;4m exceptions.UnexpectedStatusException(\u001b[0m                                       \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
       "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m8836 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[1;4mmessage=message,\u001b[0m                                                              \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
       "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m8837 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[1;4mallowed_statuses=[\u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4;33mCompleted\u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4m, \u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4;33mStopped\u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4m],\u001b[0m                                    \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
       "\u001b[38;2;255;0;0m‚îÇ\u001b[0m   \u001b[2m8838 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[1;4mactual_status=status,\u001b[0m                                                         \u001b[38;2;255;0;0m‚îÇ\u001b[0m\n",
       "\u001b[38;2;255;0;0m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\u001b[0m\n",
       "\u001b[1;91mUnexpectedStatusException: \u001b[0mError for Processing job data-wrangler-flow-processing-\u001b[1;36m02\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m27\u001b[0m-\u001b[1;36m25\u001b[0m-85db4acd: Failed. \n",
       "Reason: ClientError: ValidationException: Access denied for repository: sagemaker-data-wrangler-container in \n",
       "registry ID: \u001b[1;36m599662218115\u001b[0m. Please check if your ECR repository and image exist and role \n",
       "arn:aws:iam::\u001b[1;36m417311687551\u001b[0m:role/service-role/AmazonSageMaker-ExecutionRole-20251101T200692 has proper pull \n",
       "permissions for SageMaker: ecr:BatchCheckLayerAvailability, ecr:BatchGetImage, ecr:GetDownloadUrlForLayer\n",
       "        status code: \u001b[1;36m400\u001b[0m, request id: \u001b[93me5155cd2-f047-496d-aee9-2e668e099803\u001b[0m. Check troubleshooting guide for common \n",
       "errors: \u001b[4;38;2;0;105;255mhttps://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-python-sdk-troubleshooting.html\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"iam_role: {iam_role}\")\n",
    "job_result = sess.wait_for_processing_job(processing_job_name)\n",
    "job_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e14505",
   "metadata": {},
   "source": [
    "You can view newly created feature group in Studio, refer to [Use Amazon SageMaker Feature Store with Amazon SageMaker Studio](https://docs.aws.amazon.com/sagemaker/latest/dg/feature-store-use-with-studio.html)\n",
    "for detailed guide.[Learn more about SageMaker Feature Store](https://github.com/aws/amazon-sagemaker-examples/tree/master/sagemaker-featurestore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61e9118e-40f9-491e-9baa-cfac8f76ba9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline to ingest data is not working, hence, i exported data to S3\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker import get_execution_role\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "import logging\n",
    "import boto3\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83bcbe7-2251-49b3-82c9-8e5dc971d005",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11af594-8f58-4b9b-8d9d-901cfc2f49f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b4d5419-3c56-4b10-b3d9-95598659ee91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker_execution_role: arn:aws:iam::417311687551:role/service-role/AmazonSageMaker-ExecutionRole-20251101T200692 ; session: Session(region_name='us-east-1')\n",
      "default_bucket: sagemaker-us-east-1-417311687551 ; prefix: sagemaker-featurestore-workshop s3: s3.ServiceResource()\n"
     ]
    }
   ],
   "source": [
    "# Essentials\n",
    "sagemaker_execution_role = get_execution_role()\n",
    "session = boto3.Session()\n",
    "sagemaker_session = sagemaker.Session()\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "prefix = 'sagemaker-featurestore-workshop'\n",
    "s3 = session.resource('s3')\n",
    "print(f\"sagemaker_execution_role: {sagemaker_execution_role} ; session: {session}\")\n",
    "print(f\"default_bucket: {default_bucket} ; prefix: {prefix} s3: {s3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "541c47a4-0b0c-42c4-9f4b-67999928b536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retained</th>\n",
       "      <th>custid</th>\n",
       "      <th>created</th>\n",
       "      <th>firstorder</th>\n",
       "      <th>lastorder</th>\n",
       "      <th>esent</th>\n",
       "      <th>eopenrate</th>\n",
       "      <th>eclickrate</th>\n",
       "      <th>avgorder</th>\n",
       "      <th>ordfreq</th>\n",
       "      <th>paperless</th>\n",
       "      <th>refill</th>\n",
       "      <th>doorstep</th>\n",
       "      <th>favday</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4363.0</td>\n",
       "      <td>2012-09-28T00:00:00.000Z</td>\n",
       "      <td>2013-08-11T00:00:00.000Z</td>\n",
       "      <td>2013-08-11T00:00:00.000Z</td>\n",
       "      <td>29</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>3.448276</td>\n",
       "      <td>14.52</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8433.0</td>\n",
       "      <td>2010-12-19T00:00:00.000Z</td>\n",
       "      <td>2011-04-01T00:00:00.000Z</td>\n",
       "      <td>2014-01-19T00:00:00.000Z</td>\n",
       "      <td>95</td>\n",
       "      <td>92.631579</td>\n",
       "      <td>10.526316</td>\n",
       "      <td>83.69</td>\n",
       "      <td>0.181641</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>5709.0</td>\n",
       "      <td>2010-10-03T00:00:00.000Z</td>\n",
       "      <td>2010-12-01T00:00:00.000Z</td>\n",
       "      <td>2011-07-06T00:00:00.000Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.58</td>\n",
       "      <td>0.059908</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5866.0</td>\n",
       "      <td>2010-10-22T00:00:00.000Z</td>\n",
       "      <td>2011-03-28T00:00:00.000Z</td>\n",
       "      <td>2011-03-28T00:00:00.000Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.96</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6694.0</td>\n",
       "      <td>2010-11-27T00:00:00.000Z</td>\n",
       "      <td>2010-11-29T00:00:00.000Z</td>\n",
       "      <td>2013-01-28T00:00:00.000Z</td>\n",
       "      <td>30</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>111.91</td>\n",
       "      <td>0.008850</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   retained  custid                   created                firstorder  \\\n",
       "0         0  4363.0  2012-09-28T00:00:00.000Z  2013-08-11T00:00:00.000Z   \n",
       "1         1  8433.0  2010-12-19T00:00:00.000Z  2011-04-01T00:00:00.000Z   \n",
       "2         0  5709.0  2010-10-03T00:00:00.000Z  2010-12-01T00:00:00.000Z   \n",
       "3         0  5866.0  2010-10-22T00:00:00.000Z  2011-03-28T00:00:00.000Z   \n",
       "4         1  6694.0  2010-11-27T00:00:00.000Z  2010-11-29T00:00:00.000Z   \n",
       "\n",
       "                  lastorder  esent   eopenrate  eclickrate  avgorder  \\\n",
       "0  2013-08-11T00:00:00.000Z     29  100.000000    3.448276     14.52   \n",
       "1  2014-01-19T00:00:00.000Z     95   92.631579   10.526316     83.69   \n",
       "2  2011-07-06T00:00:00.000Z      0    0.000000    0.000000     33.58   \n",
       "3  2011-03-28T00:00:00.000Z      0    0.000000    0.000000     54.96   \n",
       "4  2013-01-28T00:00:00.000Z     30   90.000000   13.333333    111.91   \n",
       "\n",
       "    ordfreq  paperless  refill  doorstep  favday  city  \n",
       "0  0.000000          0       0         0     0.0   1.0  \n",
       "1  0.181641          1       1         1     2.0   1.0  \n",
       "2  0.059908          0       0         0     4.0   1.0  \n",
       "3  0.000000          0       0         0     3.0   0.0  \n",
       "4  0.008850          0       0         0     0.0   0.0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load transformed data\n",
    "df = pd.read_csv('s3://sagemaker-us-east-1-417311687551/output_6cb0e7fa-5fcc-4b43-b35c-4fd063839860/part-00000-82fd5d50-8a2c-4f11-95ac-e1061cda2d8d-c000.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5bc61b0e-7e38-4a2c-bb8e-29fb3935b2ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30758, 15)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ffff200a-375f-48f3-b6a4-2c331fc10e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# split data\n",
    "train_df, validation_df, test_df = np.split(df.sample(frac=1, random_state=123), [int(.7*len(df)), int(.9*len(df))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2bce8643-a85a-48ce-b102-01b4e82af172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df.shape: (21530, 15) ; validation_df.shape: (6152, 15) ; test_df.shape: (3076, 15)\n"
     ]
    }
   ],
   "source": [
    "# print data shape\n",
    "print(f\"train_df.shape: {train_df.shape} ; validation_df.shape: {validation_df.shape} ; test_df.shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2c12557a-08e9-46a2-a5d1-01d1ba1663eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save split data to local\n",
    "train_df.to_csv('../train.csv', index=False)\n",
    "validation_df.to_csv('../validation.csv', index=False)\n",
    "test_df.to_csv('../test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b2d4535e-ebb3-4521-96a5-e630dac34cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy datasets to S3 from local\n",
    "s3.Bucket(default_bucket).Object(os.path.join(prefix, 'train/train.csv')).upload_file('../train.csv')\n",
    "s3.Bucket(default_bucket).Object(os.path.join(prefix, 'validation/validation.csv')).upload_file('../validation.csv')\n",
    "s3.Bucket(default_bucket).Object(os.path.join(prefix, 'test/test.csv')).upload_file('../test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7ce0cc04-8791-4fe8-aa53-76baa8eb68b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pointers to the uploaded files\n",
    "train_set_location = 's3://{}/{}/train/'.format(default_bucket, prefix)\n",
    "validation_set_location = 's3://{}/{}/validation/'.format(default_bucket, prefix)\n",
    "test_set_location = 's3://{}/{}/test/'.format(default_bucket, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ae73d7b8-4e0d-41fe-a86f-bcfcc775f300",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_pointer = TrainingInput(s3_data=train_set_location, content_type='csv')\n",
    "validation_set_pointer = TrainingInput(s3_data=validation_set_location, content_type='csv')\n",
    "test_set_pointer = TrainingInput(s3_data=test_set_location, content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c2672d47-ca5d-43b0-ae11-64a47f2c3e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"config\": {\n",
      "    \"DataSource\": {\n",
      "      \"S3DataSource\": {\n",
      "        \"S3DataType\": \"S3Prefix\",\n",
      "        \"S3Uri\": \"s3://sagemaker-us-east-1-417311687551/sagemaker-featurestore-workshop/train/\",\n",
      "        \"S3DataDistributionType\": \"FullyReplicated\"\n",
      "      }\n",
      "    },\n",
      "    \"ContentType\": \"csv\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(train_set_pointer.__dict__, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a02d39-8553-4197-8f59-d2bec91a3a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a model using SageMaker built-in XgBoost algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "465fb2ba-4eb0-48c7-9c88-0ea821bd49d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n",
      "INFO:sagemaker.image_uris:Defaulting to only supported image scope: cpu.\n"
     ]
    }
   ],
   "source": [
    "container_uri = sagemaker.image_uris.retrieve(region=session.region_name, \n",
    "                                              framework='xgboost', \n",
    "                                              version='1.0-1', \n",
    "                                              image_scope='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "293f1986-942d-423f-bace-54582992de37",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = sagemaker.estimator.Estimator(image_uri=container_uri,\n",
    "                                    role=sagemaker_execution_role, \n",
    "                                    instance_count=2, \n",
    "                                    instance_type='ml.m5.xlarge',\n",
    "                                    output_path='s3://{}/{}/model-artifacts'.format(default_bucket, prefix),\n",
    "                                    sagemaker_session=sagemaker_session,\n",
    "                                    base_job_name='reorder-classifier')\n",
    "\n",
    "xgb.set_hyperparameters(objective='binary:logistic',\n",
    "                        num_round=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c054c88c-6eae-411b-9fc3-5e3595aa5701",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.telemetry.telemetry_logging:SageMaker Python SDK will collect telemetry to help us better understand our user's needs, diagnose issues, and deliver additional features.\n",
      "To opt out of telemetry, please disable via TelemetryOptOut parameter in SDK defaults config. For more information, refer to https://sagemaker.readthedocs.io/en/stable/overview.html#configuring-and-using-defaults-with-the-sagemaker-python-sdk.\n",
      "INFO:sagemaker:Creating training-job with name: reorder-classifier-2025-12-02-02-13-32-287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02 02:13:33 Starting - Starting the training job...\n",
      "2025-12-02 02:13:50 Starting - Preparing the instances for training...\n",
      "2025-12-02 02:14:36 Downloading - Downloading the training image......\n",
      "2025-12-02 02:15:16 Training - Training image download completed. Training in progress.\u001b[35m[2025-12-02 02:15:26.309 ip-10-0-242-116.ec2.internal:7 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[35mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[35mINFO:sagemaker-containers:Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[35mReturning the value itself\u001b[0m\n",
      "\u001b[35mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35mINFO:sagemaker_xgboost_container.training:Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[35mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35mINFO:root:Distributed node training with 2 hosts: ['algo-1', 'algo-2']\u001b[0m\n",
      "\u001b[35mINFO:RabitContextManager:Failed to connect to RabitTracker on attempt 0\u001b[0m\n",
      "\u001b[35mINFO:RabitContextManager:Sleeping for 3 sec before retrying\u001b[0m\n",
      "\u001b[35mINFO:RabitContextManager:Connected to RabitTracker.\u001b[0m\n",
      "\u001b[35mINFO:RabitContextManager:Failed to connect to RabitTracker on attempt 0\u001b[0m\n",
      "\u001b[35mINFO:RabitContextManager:Sleeping for 3 sec before retrying\u001b[0m\n",
      "\u001b[34m[2025-12-02 02:15:27.547 ip-10-0-197-224.ec2.internal:7 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Distributed node training with 2 hosts: ['algo-1', 'algo-2']\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:start listen on algo-1:9099\u001b[0m\n",
      "\u001b[34mINFO:RabitContextManager:Rabit slave environment: {'DMLC_TRACKER_URI': 'algo-1', 'DMLC_TRACKER_PORT': 9099}\u001b[0m\n",
      "\u001b[34mINFO:RabitContextManager:Connected to RabitTracker.\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:No data received from connection ('10.0.197.224', 51322). Closing.\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:No data received from connection ('10.0.242.116', 43420). Closing.\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:Recieve start signal from 10.0.197.224; assign rank 0\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:Recieve start signal from 10.0.242.116; assign rank 1\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:@tracker All of 2 nodes getting started\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:@tracker All nodes finishes job\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:@tracker 0.17284297943115234 secs between node start and job finish\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:start listen on algo-1:9100\u001b[0m\n",
      "\u001b[34mINFO:RabitContextManager:Rabit slave environment: {'DMLC_TRACKER_URI': 'algo-1', 'DMLC_TRACKER_PORT': 9100}\u001b[0m\n",
      "\u001b[34mINFO:RabitContextManager:Connected to RabitTracker.\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:No data received from connection ('10.0.197.224', 53796). Closing.\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:No data received from connection ('10.0.242.116', 50510). Closing.\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:Recieve start signal from 10.0.197.224; assign rank 0\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:Recieve start signal from 10.0.242.116; assign rank 1\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:@tracker All of 2 nodes getting started\u001b[0m\n",
      "\u001b[34m[02:15:27] 21531x14 matrix with 301434 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[02:15:27] 6153x14 matrix with 86142 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[2025-12-02 02:15:33.024 ip-10-0-197-224.ec2.internal:7 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2025-12-02 02:15:33.025 ip-10-0-197-224.ec2.internal:7 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2025-12-02 02:15:33.025 ip-10-0-197-224.ec2.internal:7 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2025-12-02 02:15:33.026 ip-10-0-197-224.ec2.internal:7 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2025-12-02 02:15:33.026 ip-10-0-197-224.ec2.internal:7 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34mINFO:root:Debug hook created from config\u001b[0m\n",
      "\u001b[34mINFO:root:Train matrix has 21531 rows\u001b[0m\n",
      "\u001b[34mINFO:root:Validation matrix has 6153 rows\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[0]#011train-error:0.03832#011validation-error:0.04047\u001b[0m\n",
      "\u001b[34m[02:15:33] WARNING: /workspace/src/learner.cc:328: \u001b[0m\n",
      "\u001b[34mParameters: { num_round } might not be used.\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\u001b[0m\n",
      "\u001b[34m[02:15:33] WARNING: /workspace/src/gbm/gbtree.cc:128: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[34m[2025-12-02 02:15:33.195 ip-10-0-197-224.ec2.internal:7 INFO hook.py:423] Monitoring the collections: metrics\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[1]#011train-error:0.03613#011validation-error:0.03949\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[2]#011train-error:0.03507#011validation-error:0.03803\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[3]#011train-error:0.03497#011validation-error:0.03819\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[4]#011train-error:0.03479#011validation-error:0.03868\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[5]#011train-error:0.03414#011validation-error:0.03852\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[6]#011train-error:0.03428#011validation-error:0.03738\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[7]#011train-error:0.03353#011validation-error:0.03624\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[8]#011train-error:0.03302#011validation-error:0.03673\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[9]#011train-error:0.03265#011validation-error:0.03657\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[10]#011train-error:0.03270#011validation-error:0.03722\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[11]#011train-error:0.03274#011validation-error:0.03705\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[12]#011train-error:0.03232#011validation-error:0.03738\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[13]#011train-error:0.03205#011validation-error:0.03673\u001b[0m\n",
      "\u001b[35mINFO:RabitContextManager:Connected to RabitTracker.\u001b[0m\n",
      "\u001b[35m[02:15:26] 21531x14 matrix with 301434 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[35m[02:15:26] 6153x14 matrix with 86142 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[35m[2025-12-02 02:15:33.024 ip-10-0-242-116.ec2.internal:7 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[35m[2025-12-02 02:15:33.025 ip-10-0-242-116.ec2.internal:7 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[35m[2025-12-02 02:15:33.025 ip-10-0-242-116.ec2.internal:7 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[35m[2025-12-02 02:15:33.026 ip-10-0-242-116.ec2.internal:7 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[35m[2025-12-02 02:15:33.026 ip-10-0-242-116.ec2.internal:7 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[35mINFO:root:Debug hook created from config\u001b[0m\n",
      "\u001b[35mINFO:root:Train matrix has 21531 rows\u001b[0m\n",
      "\u001b[35mINFO:root:Validation matrix has 6153 rows\u001b[0m\n",
      "\u001b[35m[02:15:33] WARNING: /workspace/src/learner.cc:328: \u001b[0m\n",
      "\u001b[35mParameters: { num_round } might not be used.\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\u001b[0m\n",
      "\u001b[35m[02:15:33] WARNING: /workspace/src/gbm/gbtree.cc:128: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[35m[2025-12-02 02:15:33.195 ip-10-0-242-116.ec2.internal:7 INFO hook.py:423] Monitoring the collections: metrics\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[14]#011train-error:0.03200#011validation-error:0.03689\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[15]#011train-error:0.03186#011validation-error:0.03640\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[16]#011train-error:0.03149#011validation-error:0.03640\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[17]#011train-error:0.03154#011validation-error:0.03689\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[18]#011train-error:0.03079#011validation-error:0.03738\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[19]#011train-error:0.03065#011validation-error:0.03722\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[20]#011train-error:0.03019#011validation-error:0.03673\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[21]#011train-error:0.02968#011validation-error:0.03657\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[22]#011train-error:0.02968#011validation-error:0.03673\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[23]#011train-error:0.02917#011validation-error:0.03689\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[24]#011train-error:0.02907#011validation-error:0.03657\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[25]#011train-error:0.02907#011validation-error:0.03640\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[26]#011train-error:0.02889#011validation-error:0.03608\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[27]#011train-error:0.02893#011validation-error:0.03608\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[28]#011train-error:0.02814#011validation-error:0.03608\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[29]#011train-error:0.02801#011validation-error:0.03592\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[30]#011train-error:0.02787#011validation-error:0.03576\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[31]#011train-error:0.02777#011validation-error:0.03576\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[32]#011train-error:0.02754#011validation-error:0.03640\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[33]#011train-error:0.02689#011validation-error:0.03673\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[34]#011train-error:0.02689#011validation-error:0.03640\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[35]#011train-error:0.02666#011validation-error:0.03657\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[36]#011train-error:0.02596#011validation-error:0.03673\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[37]#011train-error:0.02536#011validation-error:0.03771\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[38]#011train-error:0.02466#011validation-error:0.03738\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[39]#011train-error:0.02434#011validation-error:0.03754\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[40]#011train-error:0.02420#011validation-error:0.03754\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[41]#011train-error:0.02401#011validation-error:0.03754\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[42]#011train-error:0.02373#011validation-error:0.03771\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[43]#011train-error:0.02294#011validation-error:0.03771\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[44]#011train-error:0.02276#011validation-error:0.03754\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[45]#011train-error:0.02243#011validation-error:0.03738\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[46]#011train-error:0.02178#011validation-error:0.03722\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[47]#011train-error:0.02146#011validation-error:0.03738\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[48]#011train-error:0.02113#011validation-error:0.03738\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[49]#011train-error:0.02085#011validation-error:0.03722\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[50]#011train-error:0.02044#011validation-error:0.03640\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[51]#011train-error:0.02030#011validation-error:0.03673\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[52]#011train-error:0.01974#011validation-error:0.03624\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[53]#011train-error:0.01913#011validation-error:0.03624\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[54]#011train-error:0.01900#011validation-error:0.03592\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[55]#011train-error:0.01867#011validation-error:0.03576\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[56]#011train-error:0.01844#011validation-error:0.03640\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[57]#011train-error:0.01844#011validation-error:0.03657\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[58]#011train-error:0.01830#011validation-error:0.03657\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[59]#011train-error:0.01835#011validation-error:0.03624\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[60]#011train-error:0.01779#011validation-error:0.03657\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[61]#011train-error:0.01705#011validation-error:0.03576\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[62]#011train-error:0.01667#011validation-error:0.03576\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[63]#011train-error:0.01607#011validation-error:0.03624\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[64]#011train-error:0.01593#011validation-error:0.03624\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[65]#011train-error:0.01574#011validation-error:0.03640\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[66]#011train-error:0.01551#011validation-error:0.03738\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[67]#011train-error:0.01537#011validation-error:0.03689\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[68]#011train-error:0.01514#011validation-error:0.03722\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[69]#011train-error:0.01491#011validation-error:0.03705\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[70]#011train-error:0.01486#011validation-error:0.03689\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[71]#011train-error:0.01426#011validation-error:0.03689\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[72]#011train-error:0.01412#011validation-error:0.03722\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[73]#011train-error:0.01389#011validation-error:0.03738\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[74]#011train-error:0.01375#011validation-error:0.03738\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[75]#011train-error:0.01338#011validation-error:0.03836\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[76]#011train-error:0.01314#011validation-error:0.03819\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[77]#011train-error:0.01286#011validation-error:0.03819\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[78]#011train-error:0.01268#011validation-error:0.03852\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[79]#011train-error:0.01259#011validation-error:0.03852\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[80]#011train-error:0.01254#011validation-error:0.03787\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[81]#011train-error:0.01240#011validation-error:0.03803\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[82]#011train-error:0.01208#011validation-error:0.03803\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[83]#011train-error:0.01203#011validation-error:0.03852\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[84]#011train-error:0.01142#011validation-error:0.03900\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[85]#011train-error:0.01115#011validation-error:0.03852\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[86]#011train-error:0.01119#011validation-error:0.03852\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[87]#011train-error:0.01091#011validation-error:0.03819\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[88]#011train-error:0.01068#011validation-error:0.03868\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[89]#011train-error:0.01054#011validation-error:0.03836\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[90]#011train-error:0.01040#011validation-error:0.03819\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[91]#011train-error:0.01031#011validation-error:0.03836\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[92]#011train-error:0.01026#011validation-error:0.03836\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[93]#011train-error:0.00994#011validation-error:0.03803\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[94]#011train-error:0.00985#011validation-error:0.03868\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[95]#011train-error:0.00975#011validation-error:0.03819\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[96]#011train-error:0.00952#011validation-error:0.03771\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[97]#011train-error:0.00929#011validation-error:0.03819\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[98]#011train-error:0.00938#011validation-error:0.03836\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:[99]#011train-error:0.00906#011validation-error:0.03884\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:@tracker All nodes finishes job\u001b[0m\n",
      "\u001b[34mINFO:RabitTracker:@tracker 16.39807677268982 secs between node start and job finish\u001b[0m\n",
      "\n",
      "2025-12-02 02:16:05 Uploading - Uploading generated training model\n",
      "2025-12-02 02:16:05 Completed - Training job completed\n",
      "Training seconds: 230\n",
      "Billable seconds: 230\n"
     ]
    }
   ],
   "source": [
    "xgb.fit({'train': train_set_pointer, 'validation': validation_set_pointer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "90f03f7b-7516-4865-a82d-e121f29c66f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'training_jobName' (str)\n"
     ]
    }
   ],
   "source": [
    "# Saving Training Job Information\n",
    "# Saving training job information to be used in the ML lineage module\n",
    "training_job_info = xgb.latest_training_job.describe()\n",
    "if training_job_info != None :\n",
    "    training_jobName = training_job_info[\"TrainingJobName\"]\n",
    "    %store training_jobName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "925e3fee-f579-447d-a769-e66aad9e6375",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: reorder-classifier-2025-12-02-02-29-35-552\n",
      "INFO:sagemaker:Creating endpoint-config with name reorder-classifier-2025-12-02-02-29-35-552\n",
      "INFO:sagemaker:Creating endpoint with name reorder-classifier-2025-12-02-02-29-35-552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------!"
     ]
    }
   ],
   "source": [
    "# Host the trained XGBoost model as a SageMaker Endpoint\n",
    "xgb_predictor = xgb.deploy(initial_instance_count=2,\n",
    "                           instance_type='ml.m5.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8a0a0fe0-3080-48ef-9a3d-8447e280ace6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'endpoint_name' (str)\n"
     ]
    }
   ],
   "source": [
    "# Real time inference using the deployed endpoint\n",
    "csv_serializer = CSVSerializer()\n",
    "endpoint_name = xgb_predictor.endpoint_name\n",
    "%store endpoint_name\n",
    "predictor = Predictor(endpoint_name=endpoint_name, \n",
    "                      serializer=csv_serializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "343e7835-fe86-4125-b179-be2f527bfbc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retained</th>\n",
       "      <th>custid</th>\n",
       "      <th>created</th>\n",
       "      <th>firstorder</th>\n",
       "      <th>lastorder</th>\n",
       "      <th>esent</th>\n",
       "      <th>eopenrate</th>\n",
       "      <th>eclickrate</th>\n",
       "      <th>avgorder</th>\n",
       "      <th>ordfreq</th>\n",
       "      <th>paperless</th>\n",
       "      <th>refill</th>\n",
       "      <th>doorstep</th>\n",
       "      <th>favday</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2964</th>\n",
       "      <td>0</td>\n",
       "      <td>18054.0</td>\n",
       "      <td>2011-11-22T00:00:00.000Z</td>\n",
       "      <td>2011-11-22T00:00:00.000Z</td>\n",
       "      <td>2013-05-20T00:00:00.000Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.64</td>\n",
       "      <td>0.018349</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      retained   custid                   created                firstorder  \\\n",
       "2964         0  18054.0  2011-11-22T00:00:00.000Z  2011-11-22T00:00:00.000Z   \n",
       "\n",
       "                     lastorder  esent  eopenrate  eclickrate  avgorder  \\\n",
       "2964  2013-05-20T00:00:00.000Z      0        0.0         0.0     76.64   \n",
       "\n",
       "       ordfreq  paperless  refill  doorstep  favday  city  \n",
       "2964  0.018349          0       0         0     4.0   1.0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('../test.csv')\n",
    "record = test_df.sample(1)\n",
    "record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "85282551-2ead-45d3-94a8-cba19f18e417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18054.0, '2011-11-22T00:00:00.000Z', '2011-11-22T00:00:00.000Z',\n",
       "       '2013-05-20T00:00:00.000Z', 0, 0.0, 0.0, 76.64, 0.018348624, 0, 0,\n",
       "       0, 4.0, 1.0], dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = record.values[0]\n",
    "payload = X[1:]\n",
    "payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7da9cb6-e67b-49fd-a806-2ff3681dfc71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f08fc4-9903-4201-b68e-33426faf9f6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e663c805-6b4b-4c60-ad49-4f004ca6e769",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
